{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Импорты</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отключениие warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прочитаю обработанные ранее датасеты - без обработки пропусков, с KNN обработкой и с Iterative обработкой:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_train=pd.read_csv('../data/train_test/train.csv')\n",
    "df_raw_test=pd.read_csv('../data/train_test/test.csv')\n",
    "\n",
    "df_knn_train=pd.read_csv('../data/train_test/train_knn_imputer.csv')\n",
    "df_knn_test=pd.read_csv('../data/train_test/test_knn_imputer.csv')\n",
    "\n",
    "df_iter_train=pd.read_csv('../data/train_test/train_iter_imputer.csv')\n",
    "df_iter_test=pd.read_csv('../data/train_test/test_iter_imputer.csv')\n",
    "\n",
    "dfs={\n",
    "    'raw':{'train':df_raw_train,'test':df_raw_test},\n",
    "    'knn':{'train':df_knn_train,'test':df_knn_test},\n",
    "    'iter':{'train':df_iter_train,'test':df_iter_test}\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_object(path:str):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "pipe=load_object('d:\\\\BankProject1\\\\pipelines\\\\knn_preproc8.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_subset=list(df_raw_train.select_dtypes(['float64','int64']).columns)\n",
    "categoric_subset=list(df_raw_train.select_dtypes('object').columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определю поднаборы признаков:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "client_subset=['age','job','marital','education','default','housing','loan']\n",
    "cur_campaign_subset=['contact','month','day_of_week','duration','campaign','subscribed']\n",
    "last_campaign_subset=['pdays','previous','poutcome']\n",
    "soc_econom_subset=['emp.var.rate','cons.price.idx','cons.conf.idx','euribor3m','nr.employed']\n",
    "\n",
    "numeric_subset=list(df_raw_train.select_dtypes(['float64','int64']).columns)\n",
    "categoric_subset=list(df_raw_train.select_dtypes('object').columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определю колонки, которые будут использованы после OneHot кодирования категориальных признаков для наборов с неизвестными значениями и без них, а также пределю длины для соответствующих наборов колонок, для дальнейшего использования при создании новых, предобработанных, датасетов:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "onehot_categoric_columns_with_unknown=[]\n",
    "for cat_col in categoric_subset:\n",
    "    for val in pd.unique(df_raw_train[cat_col]):\n",
    "        new_column=f'{cat_col}_{val}'\n",
    "        onehot_categoric_columns_with_unknown.append(new_column)\n",
    "\n",
    "onehot_categoric_columns_without_unknown=[]\n",
    "for cat_col in categoric_subset:\n",
    "    for val in pd.unique(df_knn_train[cat_col]):\n",
    "        new_column=f'{cat_col}_{val}'\n",
    "        onehot_categoric_columns_without_unknown.append(new_column)\n",
    "\n",
    "\n",
    "raw_columns_lenght=len(df_raw_train.columns)\n",
    "columns_onehot_lenght_with_unknown=len(numeric_subset+onehot_categoric_columns_with_unknown)\n",
    "columns_onehot_lenght_without_unknown=len(numeric_subset+onehot_categoric_columns_without_unknown)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определю все пайплайны для предобработки данных, с помощью корорых буду формировать предобработанные датасеты, из которых на следующем этапе выберу наиболее эффективный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "preproc1\n",
      "\t for numeric: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "\t for categoric: <class 'sklearn.preprocessing._encoders.OneHotEncoder'>\n",
      "\t encoded categoric scaler: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "preproc2\n",
      "\t for numeric: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "\t for categoric: <class 'sklearn.preprocessing._encoders.OneHotEncoder'>\n",
      "\t encoded categoric scaler: <class 'sklearn.preprocessing._data.MinMaxScaler'>\n",
      "preproc3\n",
      "\t for numeric: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "\t for categoric: <class 'sklearn.preprocessing._encoders.OrdinalEncoder'>\n",
      "\t encoded categoric scaler: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "preproc4\n",
      "\t for numeric: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "\t for categoric: <class 'sklearn.preprocessing._encoders.OrdinalEncoder'>\n",
      "\t encoded categoric scaler: <class 'sklearn.preprocessing._data.MinMaxScaler'>\n",
      "preproc5\n",
      "\t for numeric: <class 'sklearn.preprocessing._data.MinMaxScaler'>\n",
      "\t for categoric: <class 'sklearn.preprocessing._encoders.OneHotEncoder'>\n",
      "\t encoded categoric scaler: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "preproc6\n",
      "\t for numeric: <class 'sklearn.preprocessing._data.MinMaxScaler'>\n",
      "\t for categoric: <class 'sklearn.preprocessing._encoders.OneHotEncoder'>\n",
      "\t encoded categoric scaler: <class 'sklearn.preprocessing._data.MinMaxScaler'>\n",
      "preproc7\n",
      "\t for numeric: <class 'sklearn.preprocessing._data.MinMaxScaler'>\n",
      "\t for categoric: <class 'sklearn.preprocessing._encoders.OrdinalEncoder'>\n",
      "\t encoded categoric scaler: <class 'sklearn.preprocessing._data.StandardScaler'>\n",
      "preproc8\n",
      "\t for numeric: <class 'sklearn.preprocessing._data.MinMaxScaler'>\n",
      "\t for categoric: <class 'sklearn.preprocessing._encoders.OrdinalEncoder'>\n",
      "\t encoded categoric scaler: <class 'sklearn.preprocessing._data.MinMaxScaler'>\n"
     ]
    }
   ],
   "source": [
    "piplines=[]\n",
    "\n",
    "std_scaler = StandardScaler()\n",
    "minmax_scaler=MinMaxScaler()\n",
    "\n",
    "ohe_encoder = OneHotEncoder(handle_unknown='ignore',sparse=False)\n",
    "original_encoder=OrdinalEncoder(handle_unknown='use_encoded_value',unknown_value=-1)\n",
    "\n",
    "num_scalers=[std_scaler,minmax_scaler]\n",
    "cat_encoders=[ohe_encoder,original_encoder]\n",
    "\n",
    "counter=1\n",
    "for scaler in num_scalers:\n",
    "    for encoder in cat_encoders:\n",
    "        pipe_num=Pipeline([('scaler',scaler)])\n",
    "        for cat_scaling in num_scalers:\n",
    "\n",
    "            pipe_cat=Pipeline([('encoder',encoder),('scaler',cat_scaling)])\n",
    "            col_transformer = ColumnTransformer([('num_preproc', pipe_num, numeric_subset),('cat_preproc', pipe_cat, categoric_subset)])\n",
    "           \n",
    "            pipe_name=f'preproc{counter}'\n",
    "            pipe=Pipeline([(pipe_name, col_transformer)])\n",
    "            piplines.append(pipe)\n",
    "\n",
    "            # вывод конфигурации каждого конвеера\n",
    "            print(pipe_name)\n",
    "            print('\\t for numeric:', scaler.__class__)\n",
    "            print('\\t for categoric:', encoder.__class__)\n",
    "            print('\\t encoded categoric scaler:', cat_scaling.__class__)\n",
    "\n",
    "            counter+=1\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Преобразую исходные датасеты через сознанные конвееры предобработки и сохраню их в .csv формате."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw\n",
      "\t preproc1\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc2\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc3\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc4\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc5\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc6\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc7\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc8\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "knn\n",
      "\t preproc1\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc2\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc3\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc4\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc5\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc6\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc7\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc8\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "iter\n",
      "\t preproc1\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc2\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc3\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc4\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc5\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc6\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc7\n",
      "\t\ttrain\n",
      "\t\ttest\n",
      "\t preproc8\n",
      "\t\ttrain\n",
      "\t\ttest\n"
     ]
    }
   ],
   "source": [
    "for key in dfs.keys():\n",
    "    print(key)\n",
    "    df_train=dfs[key]['train']\n",
    "    df_test=dfs[key]['test']\n",
    "\n",
    "    for pipe in piplines:\n",
    "        pipe_name=pipe.steps[0][0]\n",
    "        print('\\t',pipe_name)\n",
    "        prepr_df_train=pd.DataFrame(pipe.fit_transform(df_train))\n",
    "        prepr_df_test=pd.DataFrame(pipe.transform(df_test))\n",
    "\n",
    "        with open(f'../pipelines/{key}_{pipe_name}.pkl','wb') as f:\n",
    "            pickle.dump(pipe,f)\n",
    "\n",
    "        # передаю названия колонок для разных случаев кодирования признаков\n",
    "        if  len(prepr_df_train.columns)==columns_onehot_lenght_without_unknown:\n",
    "            prepr_df_train.columns=numeric_subset+onehot_categoric_columns_without_unknown\n",
    "            prepr_df_test.columns=numeric_subset+onehot_categoric_columns_without_unknown\n",
    "\n",
    "        elif len(prepr_df_train.columns)==columns_onehot_lenght_with_unknown:\n",
    "            prepr_df_train.columns=numeric_subset+onehot_categoric_columns_with_unknown\n",
    "            prepr_df_test.columns=numeric_subset+onehot_categoric_columns_with_unknown\n",
    "        else:\n",
    "            prepr_df_train.columns=numeric_subset+categoric_subset\n",
    "            prepr_df_test.columns=numeric_subset+categoric_subset\n",
    "\n",
    "        # записываю датасеты по правилу имени исходник_предобработчик_тип.csv\n",
    "        print('\\t\\ttrain')\n",
    "        prepr_df_train.to_csv(f'../data/preprocessed/{key}_{pipe_name}_train.csv',index=False)\n",
    "        print('\\t\\ttest')\n",
    "        prepr_df_test.to_csv(f'../data/preprocessed/{key}_{pipe_name}_test.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно видеть, что для каждого из трёх наборов данных было выполнено по 8 сценариев предобработки для тренировочного и тестового поднабора. Призведена кодировка и масштабирование категориальных признаков разными методами, также отмасштабированы числовые признаки.\n",
    "\n",
    "Выведу некоторые датасеты: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>emp.var.rate</th>\n",
       "      <th>cons.price.idx</th>\n",
       "      <th>cons.conf.idx</th>\n",
       "      <th>euribor3m</th>\n",
       "      <th>nr.employed</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>subscribed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.694917</td>\n",
       "      <td>-0.568265</td>\n",
       "      <td>-0.039529</td>\n",
       "      <td>-0.186533</td>\n",
       "      <td>0.133307</td>\n",
       "      <td>0.442050</td>\n",
       "      <td>1.006984</td>\n",
       "      <td>0.243595</td>\n",
       "      <td>-0.634165</td>\n",
       "      <td>-0.183837</td>\n",
       "      <td>-0.223478</td>\n",
       "      <td>-1.707922</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>-1.018237</td>\n",
       "      <td>-0.422273</td>\n",
       "      <td>0.170234</td>\n",
       "      <td>-0.242878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.802037</td>\n",
       "      <td>-0.568265</td>\n",
       "      <td>-0.039529</td>\n",
       "      <td>-0.186533</td>\n",
       "      <td>0.133307</td>\n",
       "      <td>0.442050</td>\n",
       "      <td>1.006984</td>\n",
       "      <td>0.243595</td>\n",
       "      <td>-0.634165</td>\n",
       "      <td>0.944348</td>\n",
       "      <td>-0.223478</td>\n",
       "      <td>-0.258062</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>-1.018237</td>\n",
       "      <td>-0.422273</td>\n",
       "      <td>0.170234</td>\n",
       "      <td>-0.242878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.340374</td>\n",
       "      <td>-0.568265</td>\n",
       "      <td>-0.039529</td>\n",
       "      <td>-0.186533</td>\n",
       "      <td>0.133307</td>\n",
       "      <td>0.442050</td>\n",
       "      <td>1.006984</td>\n",
       "      <td>0.243595</td>\n",
       "      <td>-0.634165</td>\n",
       "      <td>0.944348</td>\n",
       "      <td>-0.223478</td>\n",
       "      <td>-0.258062</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>0.982090</td>\n",
       "      <td>-0.422273</td>\n",
       "      <td>0.170234</td>\n",
       "      <td>-0.242878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.019012</td>\n",
       "      <td>-0.568265</td>\n",
       "      <td>-0.039529</td>\n",
       "      <td>-0.186533</td>\n",
       "      <td>0.133307</td>\n",
       "      <td>0.442050</td>\n",
       "      <td>1.006984</td>\n",
       "      <td>0.243595</td>\n",
       "      <td>-0.634165</td>\n",
       "      <td>-1.029977</td>\n",
       "      <td>-0.223478</td>\n",
       "      <td>-1.224635</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>-1.018237</td>\n",
       "      <td>-0.422273</td>\n",
       "      <td>0.170234</td>\n",
       "      <td>-0.242878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.694917</td>\n",
       "      <td>-0.568265</td>\n",
       "      <td>-0.039529</td>\n",
       "      <td>-0.186533</td>\n",
       "      <td>0.133307</td>\n",
       "      <td>0.442050</td>\n",
       "      <td>1.006984</td>\n",
       "      <td>0.243595</td>\n",
       "      <td>-0.634165</td>\n",
       "      <td>0.944348</td>\n",
       "      <td>-0.223478</td>\n",
       "      <td>-0.258062</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>-1.018237</td>\n",
       "      <td>2.368136</td>\n",
       "      <td>0.170234</td>\n",
       "      <td>-0.242878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28826</th>\n",
       "      <td>1.052193</td>\n",
       "      <td>-0.246897</td>\n",
       "      <td>-0.039529</td>\n",
       "      <td>5.009546</td>\n",
       "      <td>-3.748481</td>\n",
       "      <td>-1.765851</td>\n",
       "      <td>-2.168654</td>\n",
       "      <td>-4.651549</td>\n",
       "      <td>-3.897100</td>\n",
       "      <td>-0.747930</td>\n",
       "      <td>-0.223478</td>\n",
       "      <td>-0.741349</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>0.982090</td>\n",
       "      <td>-0.422273</td>\n",
       "      <td>-5.271025</td>\n",
       "      <td>-0.242878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28827</th>\n",
       "      <td>-1.304459</td>\n",
       "      <td>0.395839</td>\n",
       "      <td>-0.039529</td>\n",
       "      <td>5.009546</td>\n",
       "      <td>-3.748481</td>\n",
       "      <td>-1.765851</td>\n",
       "      <td>-2.168654</td>\n",
       "      <td>-4.651549</td>\n",
       "      <td>-3.897100</td>\n",
       "      <td>1.508441</td>\n",
       "      <td>1.466736</td>\n",
       "      <td>-0.258062</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>0.982090</td>\n",
       "      <td>2.368136</td>\n",
       "      <td>-5.271025</td>\n",
       "      <td>-0.242878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28828</th>\n",
       "      <td>0.088109</td>\n",
       "      <td>-0.246897</td>\n",
       "      <td>-0.039529</td>\n",
       "      <td>-0.186533</td>\n",
       "      <td>-3.748481</td>\n",
       "      <td>-1.765851</td>\n",
       "      <td>-2.168654</td>\n",
       "      <td>-4.651549</td>\n",
       "      <td>-3.897100</td>\n",
       "      <td>-0.747930</td>\n",
       "      <td>-1.913692</td>\n",
       "      <td>-1.707922</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>-1.018237</td>\n",
       "      <td>2.368136</td>\n",
       "      <td>0.170234</td>\n",
       "      <td>-0.242878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28829</th>\n",
       "      <td>-0.233253</td>\n",
       "      <td>0.074471</td>\n",
       "      <td>-0.039529</td>\n",
       "      <td>5.009546</td>\n",
       "      <td>-3.748481</td>\n",
       "      <td>-1.765851</td>\n",
       "      <td>-2.168654</td>\n",
       "      <td>-4.651549</td>\n",
       "      <td>-3.897100</td>\n",
       "      <td>1.508441</td>\n",
       "      <td>-1.913692</td>\n",
       "      <td>-0.258062</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>0.982090</td>\n",
       "      <td>2.368136</td>\n",
       "      <td>-5.271025</td>\n",
       "      <td>-0.242878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28830</th>\n",
       "      <td>-0.768856</td>\n",
       "      <td>-0.568265</td>\n",
       "      <td>21.737562</td>\n",
       "      <td>5.009546</td>\n",
       "      <td>-3.748481</td>\n",
       "      <td>-1.765851</td>\n",
       "      <td>-2.168654</td>\n",
       "      <td>-4.651549</td>\n",
       "      <td>-3.897100</td>\n",
       "      <td>-0.747930</td>\n",
       "      <td>-0.223478</td>\n",
       "      <td>-0.741349</td>\n",
       "      <td>-0.010201</td>\n",
       "      <td>-1.018237</td>\n",
       "      <td>-0.422273</td>\n",
       "      <td>5.611493</td>\n",
       "      <td>-0.242878</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>28831 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  campaign      pdays  previous  emp.var.rate  cons.price.idx  \\\n",
       "0      1.694917 -0.568265  -0.039529 -0.186533      0.133307        0.442050   \n",
       "1      1.802037 -0.568265  -0.039529 -0.186533      0.133307        0.442050   \n",
       "2     -0.340374 -0.568265  -0.039529 -0.186533      0.133307        0.442050   \n",
       "3     -0.019012 -0.568265  -0.039529 -0.186533      0.133307        0.442050   \n",
       "4      1.694917 -0.568265  -0.039529 -0.186533      0.133307        0.442050   \n",
       "...         ...       ...        ...       ...           ...             ...   \n",
       "28826  1.052193 -0.246897  -0.039529  5.009546     -3.748481       -1.765851   \n",
       "28827 -1.304459  0.395839  -0.039529  5.009546     -3.748481       -1.765851   \n",
       "28828  0.088109 -0.246897  -0.039529 -0.186533     -3.748481       -1.765851   \n",
       "28829 -0.233253  0.074471  -0.039529  5.009546     -3.748481       -1.765851   \n",
       "28830 -0.768856 -0.568265  21.737562  5.009546     -3.748481       -1.765851   \n",
       "\n",
       "       cons.conf.idx  euribor3m  nr.employed       job   marital  education  \\\n",
       "0           1.006984   0.243595    -0.634165 -0.183837 -0.223478  -1.707922   \n",
       "1           1.006984   0.243595    -0.634165  0.944348 -0.223478  -0.258062   \n",
       "2           1.006984   0.243595    -0.634165  0.944348 -0.223478  -0.258062   \n",
       "3           1.006984   0.243595    -0.634165 -1.029977 -0.223478  -1.224635   \n",
       "4           1.006984   0.243595    -0.634165  0.944348 -0.223478  -0.258062   \n",
       "...              ...        ...          ...       ...       ...        ...   \n",
       "28826      -2.168654  -4.651549    -3.897100 -0.747930 -0.223478  -0.741349   \n",
       "28827      -2.168654  -4.651549    -3.897100  1.508441  1.466736  -0.258062   \n",
       "28828      -2.168654  -4.651549    -3.897100 -0.747930 -1.913692  -1.707922   \n",
       "28829      -2.168654  -4.651549    -3.897100  1.508441 -1.913692  -0.258062   \n",
       "28830      -2.168654  -4.651549    -3.897100 -0.747930 -0.223478  -0.741349   \n",
       "\n",
       "        default   housing      loan  poutcome  subscribed  \n",
       "0     -0.010201 -1.018237 -0.422273  0.170234   -0.242878  \n",
       "1     -0.010201 -1.018237 -0.422273  0.170234   -0.242878  \n",
       "2     -0.010201  0.982090 -0.422273  0.170234   -0.242878  \n",
       "3     -0.010201 -1.018237 -0.422273  0.170234   -0.242878  \n",
       "4     -0.010201 -1.018237  2.368136  0.170234   -0.242878  \n",
       "...         ...       ...       ...       ...         ...  \n",
       "28826 -0.010201  0.982090 -0.422273 -5.271025   -0.242878  \n",
       "28827 -0.010201  0.982090  2.368136 -5.271025   -0.242878  \n",
       "28828 -0.010201 -1.018237  2.368136  0.170234   -0.242878  \n",
       "28829 -0.010201  0.982090  2.368136 -5.271025   -0.242878  \n",
       "28830 -0.010201 -1.018237 -0.422273  5.611493   -0.242878  \n",
       "\n",
       "[28831 rows x 17 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fkey='knn'\n",
    "skey='preproc7'\n",
    "tkey='train'\n",
    "\n",
    "pd.read_csv(f'../data/preprocessed/{fkey}_{skey}_{tkey}.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Датасеты сформированы корректно.\n",
    "\n",
    "Запишу их в каталог data/preprocessed для дальнейшего исследования (понижение размерности) и использования."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого записано тренировочный и тестовый надор для каждого из 8-и конвееров предобработки для каждго из трёх наборов данных, которые отличаются методом заполнения пропусков - всего 48 файлов."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
